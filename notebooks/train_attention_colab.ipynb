{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KGAT 注意力機制訓練 (極致記憶體管理版 v2)\n",
    "\n",
    "修復了 `gc` 未定義的錯誤，並進一步強化了 RAM/VRAM 的回收機制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_ROOT = \"/content/drive/MyDrive/Experiment\"\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data/processed\")\n",
    "MODEL_SAVE_DIR = os.path.join(PROJECT_ROOT, \"models\")\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用裝置: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 模型定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayerAttention(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(GNNLayerAttention, self).__init__()\n",
    "        self.W1 = nn.Linear(in_dim, out_dim)\n",
    "        self.W2 = nn.Linear(in_dim, out_dim)\n",
    "        self.W_att = nn.Linear(in_dim, out_dim)\n",
    "        self.a = nn.Parameter(torch.zeros(size=(2 * out_dim, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, indices, features, num_nodes, return_attention=False):\n",
    "        src, dst = indices[0], indices[1]\n",
    "        \n",
    "        h_trans = self.W_att(features)\n",
    "        h_src = h_trans[src]\n",
    "        h_dst = h_trans[dst]\n",
    "        del h_trans\n",
    "        \n",
    "        edge_h = torch.cat([h_src, h_dst], dim=1)\n",
    "        e_ij = self.leaky_relu(torch.matmul(edge_h, self.a))\n",
    "        del edge_h\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=False):\n",
    "            alpha = F.softmax(e_ij.float(), dim=0) # 使用 softmax 簡化測試，稍後加回 scatter softmax 如果 ok\n",
    "            # 實際上 GAT 應該是對每個 dst node 做 softmax，我們用簡化版先測通穩定性\n",
    "            \n",
    "            h_msg_all = self.W1(features.float())\n",
    "            msg = h_msg_all[src]\n",
    "            weighted_msg = msg * alpha\n",
    "            \n",
    "            h_neigh = torch.zeros(num_nodes, self.W1.out_features, device=device)\n",
    "            h_neigh.index_add_(0, dst, weighted_msg)\n",
    "            \n",
    "            del h_msg_all, msg, weighted_msg\n",
    "            \n",
    "        h_neigh = h_neigh.to(features.dtype)\n",
    "        h_self = self.W1(features) if features.shape[1] != h_neigh.shape[1] else features\n",
    "        h_out = self.leaky_relu(h_self + h_neigh + self.W2(h_self * h_neigh))\n",
    "        \n",
    "        if return_attention: return h_out, alpha\n",
    "        return h_out\n",
    "\n",
    "class KGATAttention(nn.Module):\n",
    "    def __init__(self, n_users, n_entities, n_relations, embed_dim=32, layers=[32]):\n",
    "        super(KGATAttention, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.user_embed = nn.Embedding(n_users, embed_dim)\n",
    "        self.entity_embed = nn.Embedding(n_entities, embed_dim)\n",
    "        self.relation_embed = nn.Embedding(n_relations, embed_dim)\n",
    "        self.aggregator_layers = nn.ModuleList([GNNLayerAttention(embed_dim, l) for l in layers])\n",
    "        self._init_weight()\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Embedding) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, indices, num_nodes, user_ids, item_ids, return_attention=False):\n",
    "        all_embed = torch.cat([self.user_embed.weight, self.entity_embed.weight], dim=0)\n",
    "        ego_embeddings = [all_embed]\n",
    "        for layer in self.aggregator_layers:\n",
    "            all_embed = layer(indices, all_embed, num_nodes)\n",
    "            all_embed = F.normalize(all_embed, p=2, dim=1)\n",
    "            ego_embeddings.append(all_embed)\n",
    "            \n",
    "        final_embed = torch.cat(ego_embeddings, dim=1)\n",
    "        u_embed = final_embed[user_ids]\n",
    "        i_embed = final_embed[self.n_users + item_ids]\n",
    "        return torch.sum(u_embed * i_embed, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 訓練邏輯 (強化 GC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc # 再次確保載入\n",
    "\n",
    "def load_data(dir_path):\n",
    "    with open(f\"{dir_path}/interactions.pkl\", 'rb') as f: interactions = pickle.load(f)\n",
    "    if isinstance(interactions, pd.DataFrame): interactions = interactions.values\n",
    "    with open(f\"{dir_path}/kg_triples.pkl\", 'rb') as f: kg_triples = pickle.load(f)\n",
    "    with open(f\"{dir_path}/stats.pkl\", 'rb') as f: stats = pickle.load(f)\n",
    "    return interactions, kg_triples, stats\n",
    "\n",
    "def run_training_gpu(total_epochs=20, batch_size=1024, resume_checkpoint=None):\n",
    "    interactions, kg_triples, stats = load_data(DATA_PATH)\n",
    "    n_users, n_items, n_entities = stats['n_users'], stats['n_items'], stats['n_entities']\n",
    "    \n",
    "    # 準備圖結構\n",
    "    num_nodes = n_users + n_items + n_entities\n",
    "    src = torch.from_numpy(kg_triples[:, 0] + n_users)\n",
    "    dst = torch.from_numpy(kg_triples[:, 2] + n_users + n_items)\n",
    "    indices = torch.stack([src, dst]).to(device)\n",
    "    del kg_triples, src, dst\n",
    "    gc.collect()\n",
    "    \n",
    "    model = KGATAttention(n_users, n_items + n_entities, stats['n_relations'], embed_dim=32, layers=[32]).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        model.train()\n",
    "        total_loss, n_batches = 0, len(interactions) // batch_size\n",
    "        pbar = tqdm(range(n_batches), desc=f\"Epoch {epoch+1}/{total_epochs}\")\n",
    "        \n",
    "        for _ in pbar:\n",
    "            idx = np.random.randint(0, len(interactions), batch_size)\n",
    "            batch = interactions[idx]\n",
    "            u = torch.LongTensor(batch[:, 0]).to(device)\n",
    "            i = torch.LongTensor(batch[:, 1]).to(device)\n",
    "            j = torch.LongTensor(np.random.randint(0, n_items, batch_size)).to(device)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                pos, neg = model(indices, num_nodes, u, i), model(indices, num_nodes, u, j)\n",
    "                loss = -torch.mean(torch.log(torch.sigmoid(pos - neg) + 1e-10))\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} 完成. 平均損失: {total_loss/n_batches:.4f}\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "run_training_gpu(total_epochs=20, batch_size=1024)"
   ]
  }
 ],
 "metadata": { \"kernelspec\": { \"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\" } },
 "nbformat": 4,
 "nbformat_minor": 2
}
